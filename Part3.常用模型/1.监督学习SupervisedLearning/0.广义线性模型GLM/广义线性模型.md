# 1.假设

1. y|x;θ~ExponentialFamily(η)

2. 给了x, 我们的目的是为了预测T(y)的在条件x下的期望。一般情况T(y)=y, 这就意味着我们希望预测h(x)=E[y|x]。

   这个假设在逻辑回归和线性回归中都是满足的。 比如在线性回归中：hθ(x) = p(y = 1|x; θ) = 0 · p(y =
   0|x; θ) + 1 · p(y = 1|x; θ) = E[y|x; θ]. 

3. 参数η和输入x 是线性相关的：即η=θTx。这条更被认为是“设计选择”，而不是假设。

# 2.模型的一般形式


$$
y=g^{-1}(w^Tx+b)
$$
g(·)——联系函数



# 3.GLM推导最小二乘

- MS是GLM的一个特例。
- 假设y|x;θ∼N(μ,σ2)，那么：

$$
h_\theta(x) = E[y|x;\theta] \\ =\mu \\ =\eta \\ = \theta^T x
$$

- 上式中第一行因为假设2，第二行因为高斯分布的特点，第三行根据上面高斯分布为指数族分布的推导，第四行因为假设3。

# 4.GLM推导逻辑回归

- LR是GLM的一个特例。
- 假设y|x;θ∼Bernoulli(φ)，那么：

$$
h_\theta(x) = E[y|x;\theta] \\ =\phi \\ =\frac{1}{1+e^{-\eta}} \\ = \frac{1}{1+e^{-\theta^T x}}
$$

- 第一行因为假设2，第二行因为伯努利分布的性质，第三行因为伯努利分布为指数族分布时的推导，第四行因为假设3。

# 5.GLM推导Softmax

- Softmax是GLM的一个特例
- 如果要分为k类，则使用k个参数φ1, . . . , φk，各表示属于每一类的概率。由于φ1 + . . .  + φk=1，则这里简化为k-1个参数，第k个参数由前k-1个推出来即可。
- 为了将多项式分布能够写成指数分布族的形式，先引入T(y)，它是一个k-1维的向量，如下所示：

![](https://www.2cto.com/uploadfile/Collfiles/20161219/20161219092103693.png)

- 引入指示函数1，使得：1{True} = 1，1{False} = 0。则可以将T(y)表示为：(T (y))i = 1{y = i} ，从而有：E[(T(yi))] = P(y = i) = φi。
- 可以得到：

![](https://www.2cto.com/uploadfile/Collfiles/20161219/20161219092103695.png)

- 其中：

![](https://www.2cto.com/uploadfile/Collfiles/20161219/20161219092103696.png)

- 正则关联函数如下：

$$
\eta_i=log\frac{\phi_i}{\phi_k}
$$



- 方便起见，定义：

$$
\eta_k=log\frac{\phi_k}{\phi_k}=0
$$

- 导出正则响应函数：这个变换后的φ就是Softmax函数。

$$
e^{\eta_i}=\frac{\phi_i}{\phi_k} \\ \phi_ke^{\eta_i}={\phi_i} \\ \phi_k\sum_{i=1}^ke^{\eta_i}=\sum_{i=1}^k\phi_i=1\\ \phi_k=\frac{1}{\sum_{i=1}^ke^{\eta_i}}\\ \phi_i=\frac{e^{\eta_i}}{\sum_{j=1}^ke^{\eta_j}}
$$



- 使用假设3，将ηi 和x联系起来，有：ηi = θiTx (i=1,...,k-1，θi是模型参数)。则有Sofumax回归：

$$
p(y=i|x;\theta)=\phi_i \\ =\frac{e^{\eta_i}}{\sum_{j=1}^ke^\eta_j}\\=\frac{e^{\theta_i^Tx}}{\sum_{j=1}^ke^{\theta_j^Tx}}
$$



- 向量表示的模型函数为：

![](https://www.2cto.com/uploadfile/Collfiles/20161219/20161219092103700.png)

# 6.正则响应函数

- 将η与原始概率分布中的参数联系起来的函数

- 如：
  $$
  \phi =\frac{1}{1+e^{-\eta}} （逻辑回归）、\mu =\eta（最小二乘）、\eta_i=log\frac{\phi_i}{\phi_k}（Softmax）
  $$



# 7.正则联系函数

- 正则响应函数的逆。